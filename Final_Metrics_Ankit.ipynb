{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c871f54d-a973-4f36-8891-97c301f2e8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "43db9129-a6cf-4b1e-8698-fd78acbd0808",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dataset = pd.read_csv(r'E:\\MCA\\ISI internship\\Practical project\\merged_input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ca759e7-c85c-4a9f-8c24-58eb8cc4d704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy of the main_dataset where we'll perform functions\n",
    "data = main_dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f0736736-fbee-49d9-a409-43856e7d84a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordNo</th>\n",
       "      <th>UserID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>SessionStart</th>\n",
       "      <th>SessionEnd</th>\n",
       "      <th>StartLocale</th>\n",
       "      <th>EndLocale</th>\n",
       "      <th>DayZone</th>\n",
       "      <th>DayType</th>\n",
       "      <th>...</th>\n",
       "      <th>AddToPantryItems</th>\n",
       "      <th>SavedRecipes</th>\n",
       "      <th>Pantry</th>\n",
       "      <th>DietaryPreferences</th>\n",
       "      <th>Allergy</th>\n",
       "      <th>PreferredRecipes</th>\n",
       "      <th>TabChange</th>\n",
       "      <th>UserAgent</th>\n",
       "      <th>Device</th>\n",
       "      <th>ActivityLog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>anon</td>\n",
       "      <td>2025-09-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15:11:26</td>\n",
       "      <td>15:33:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like M...</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>Viewed recipes before widget: ['P11D56R150'];A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>anon</td>\n",
       "      <td>2025-09-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18:34:08</td>\n",
       "      <td>19:02:46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Mozilla/5.0 (Android 11; Mobile; rv:89.0) Geck...</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>Viewed recipes before widget: ['P11D56R150'];A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>anon</td>\n",
       "      <td>2025-09-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13:22:06</td>\n",
       "      <td>13:48:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Mozilla/5.0 (Android 11; Mobile; rv:89.0) Geck...</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>Viewed recipes before widget: ['P11D56R150'];A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>user120</td>\n",
       "      <td>2025-09-23</td>\n",
       "      <td>Fort-de-France,Martinique</td>\n",
       "      <td>01:58:17</td>\n",
       "      <td>02:35:08</td>\n",
       "      <td>09:58 PM</td>\n",
       "      <td>10:35 PM</td>\n",
       "      <td>D</td>\n",
       "      <td>wd</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i430;i570;i650;i377;i1659;i2044;i1578;i1685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A26;A29;A24;A28;A27</td>\n",
       "      <td>P16D98R83;P7D95R50;P5D96R59;P2D26R107;P5D96R94...</td>\n",
       "      <td>True</td>\n",
       "      <td>Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like M...</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>Viewed recipes before widget: ['P1D89R157'];Wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordNo   UserID        Date                   Location SessionStart  \\\n",
       "0         1     anon  2025-09-08                        NaN     15:11:26   \n",
       "1         2     anon  2025-09-19                        NaN     18:34:08   \n",
       "2         3     anon  2025-09-08                        NaN     13:22:06   \n",
       "3         4  user120  2025-09-23  Fort-de-France,Martinique     01:58:17   \n",
       "\n",
       "  SessionEnd StartLocale EndLocale DayZone DayType  ... AddToPantryItems  \\\n",
       "0   15:33:18         NaN       NaN     NaN     NaN  ...              NaN   \n",
       "1   19:02:46         NaN       NaN     NaN     NaN  ...              NaN   \n",
       "2   13:48:08         NaN       NaN     NaN     NaN  ...              NaN   \n",
       "3   02:35:08    09:58 PM  10:35 PM       D      wd  ...              NaN   \n",
       "\n",
       "  SavedRecipes                                       Pantry  \\\n",
       "0          NaN                                          NaN   \n",
       "1          NaN                                          NaN   \n",
       "2          NaN                                          NaN   \n",
       "3          NaN  i430;i570;i650;i377;i1659;i2044;i1578;i1685   \n",
       "\n",
       "  DietaryPreferences              Allergy  \\\n",
       "0                NaN                  NaN   \n",
       "1                NaN                  NaN   \n",
       "2                NaN                  NaN   \n",
       "3                NaN  A26;A29;A24;A28;A27   \n",
       "\n",
       "                                    PreferredRecipes TabChange  \\\n",
       "0                                                NaN      True   \n",
       "1                                                NaN     False   \n",
       "2                                                NaN     False   \n",
       "3  P16D98R83;P7D95R50;P5D96R59;P2D26R107;P5D96R94...      True   \n",
       "\n",
       "                                           UserAgent   Device  \\\n",
       "0  Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like M...   Mobile   \n",
       "1  Mozilla/5.0 (Android 11; Mobile; rv:89.0) Geck...   Tablet   \n",
       "2  Mozilla/5.0 (Android 11; Mobile; rv:89.0) Geck...  Desktop   \n",
       "3  Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like M...  Desktop   \n",
       "\n",
       "                                         ActivityLog  \n",
       "0  Viewed recipes before widget: ['P11D56R150'];A...  \n",
       "1  Viewed recipes before widget: ['P11D56R150'];A...  \n",
       "2  Viewed recipes before widget: ['P11D56R150'];A...  \n",
       "3  Viewed recipes before widget: ['P1D89R157'];Wi...  \n",
       "\n",
       "[4 rows x 39 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48f3177-058e-4028-90e6-1756d58976d2",
   "metadata": {},
   "source": [
    "###\n",
    "## 1. Rare ingredients (bottom 5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f08ac23-22d4-421c-917b-4c80ca478496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rare Ingredients (Bottom 5% by Frequency):\n",
      "Ingredients\n",
      "i2040    1\n",
      "i2219    1\n",
      "i1780    1\n",
      "i303     1\n",
      "i843     1\n",
      "i2225    1\n",
      "i460     1\n",
      "i640     1\n",
      "i164     1\n",
      "i1494    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Handle missing values and ensure string format ---\n",
    "data['Ingredients'] = data['Ingredients'].fillna('').astype(str)\n",
    "\n",
    "# --- Step 2: Split ingredients by ';' and flatten into a single list ---\n",
    "all_ingredients = data['Ingredients'].str.split(';').explode().str.strip()\n",
    "all_ingredients = all_ingredients[all_ingredients != '']  # remove empty entries\n",
    "\n",
    "# --- Step 3: Calculate ingredient frequencies ---\n",
    "ingredient_freq = all_ingredients.value_counts()\n",
    "\n",
    "# --- Step 4: Determine bottom 5% rare ingredients ---\n",
    "threshold = int(len(ingredient_freq) * 0.05)\n",
    "if threshold == 0:  # handle small datasets\n",
    "    threshold = 1\n",
    "\n",
    "rare_ingredients = ingredient_freq.tail(threshold)\n",
    "\n",
    "# --- Step 5: Display rare ingredients ---\n",
    "print(\"Rare Ingredients (Bottom 5% by Frequency):\")\n",
    "print(rare_ingredients.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91c7599-bfd6-4fb8-94ec-55a9090dd015",
   "metadata": {},
   "source": [
    "###\n",
    "## 2. User Engagement Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7560e0f3-d176-43d0-8976-e4132c16d914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Engagement Trends Table:\n",
      "        Date  WidgetDuration    DayName DayInitial  WeekStart Month  WeekNum  \\\n",
      "0 2025-09-03        6.385714  Wednesday          W 2025-09-01   Sep       36   \n",
      "1 2025-09-04        4.898718   Thursday          T 2025-09-01   Sep       36   \n",
      "2 2025-09-05        5.663333     Friday          F 2025-09-01   Sep       36   \n",
      "3 2025-09-06        6.566667   Saturday          S 2025-09-01   Sep       36   \n",
      "4 2025-09-07        5.508974     Sunday          S 2025-09-01   Sep       36   \n",
      "5 2025-09-08        4.470000     Monday          M 2025-09-08   Sep       37   \n",
      "6 2025-09-09        7.808333    Tuesday          T 2025-09-08   Sep       37   \n",
      "7 2025-09-10        6.929167  Wednesday          W 2025-09-08   Sep       37   \n",
      "8 2025-09-11        5.619048   Thursday          T 2025-09-08   Sep       37   \n",
      "9 2025-09-12        3.664583     Friday          F 2025-09-08   Sep       37   \n",
      "\n",
      "   WeekOfMonth  \n",
      "0            1  \n",
      "1            1  \n",
      "2            1  \n",
      "3            1  \n",
      "4            1  \n",
      "5            2  \n",
      "6            2  \n",
      "7            2  \n",
      "8            2  \n",
      "9            2  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Filter out rows with WidgetDuration = 0\n",
    "data4 = main_dataset[main_dataset['WidgetDuration'] > 0].copy()\n",
    "\n",
    "# Step 2: Convert 'Date' to datetime safely\n",
    "data4['Date'] = pd.to_datetime(data4['Date'], errors='coerce')\n",
    "data4 = data4.dropna(subset=['Date'])\n",
    "\n",
    "# Step 3: Aggregate average WidgetDuration per date\n",
    "engagement_trends = data4.groupby('Date')['WidgetDuration'].mean().reset_index()\n",
    "\n",
    "# Step 4: Add additional date-based columns\n",
    "engagement_trends['DayName'] = engagement_trends['Date'].dt.day_name()\n",
    "engagement_trends['DayInitial'] = engagement_trends['Date'].dt.strftime('%a').str[0]\n",
    "engagement_trends['WeekStart'] = engagement_trends['Date'] - pd.to_timedelta(engagement_trends['Date'].dt.weekday, unit='D')\n",
    "engagement_trends['Month'] = engagement_trends['Date'].dt.strftime('%b')\n",
    "engagement_trends['WeekNum'] = engagement_trends['Date'].dt.isocalendar().week\n",
    "\n",
    "# Step 5: Compute \"Week of Month\"\n",
    "engagement_trends['WeekOfMonth'] = engagement_trends.groupby('Month')['WeekNum'].transform(lambda x: x - x.min() + 1)\n",
    "engagement_trends = engagement_trends.sort_values(['Date']).reset_index(drop=True)\n",
    "\n",
    "# Display the final engagement trends table\n",
    "print(\"ðŸ“Š Engagement Trends Table:\")\n",
    "print(engagement_trends.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95ef4df-1b9c-4524-a379-47fc3c0f49ab",
   "metadata": {},
   "source": [
    "###\n",
    "## 3. Dietary Preference Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5344bb0a-16cb-4291-8adb-d0ac3d09fdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DietaryPreferences\n",
      "pref0                12.727273\n",
      "pref2;pref1;pref3    10.909091\n",
      "pref1                 9.696970\n",
      "pref2;pref1;pref0     9.090909\n",
      "pref2                 9.090909\n",
      "pref3                 7.878788\n",
      "pref1;pref3;pref2     6.060606\n",
      "pref1;pref0;pref2     5.454545\n",
      "pref2;pref0           5.454545\n",
      "pref3;pref1           4.848485\n",
      "pref2;pref3           4.848485\n",
      "pref0;pref2;pref1     4.848485\n",
      "pref3;pref2           4.242424\n",
      "pref1;pref3;pref0     3.636364\n",
      "pref0;pref3;pref2     1.212121\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "dietary_distribution = data['DietaryPreferences'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(dietary_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08ecc85-7395-40a2-84ba-dab37cf5ab34",
   "metadata": {},
   "source": [
    "###\n",
    "## 4. Average Widget Load Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "29537c9b-7166-48fa-80c2-a1982207ae00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Widget Load Time: 2.79 seconds\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'WidgetLoadTime' is numeric\n",
    "data2['WidgetLoadTime'] = pd.to_numeric(data2['WidgetLoadTime'], errors='coerce')\n",
    "\n",
    "# Drop missing values\n",
    "data2 = data2.dropna(subset=['WidgetLoadTime'])\n",
    "\n",
    "# Calculate average widget load time\n",
    "avg_load_time = data2['WidgetLoadTime'].mean()\n",
    "\n",
    "print(f\"Average Widget Load Time: {avg_load_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9dc5f5-fb02-4055-b22a-91c0739f56fd",
   "metadata": {},
   "source": [
    "###\n",
    "## 5.  Average Widget Duration per UserID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1d91e336-f146-4c03-86d8-7b2af1604b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    UserID  AvgWidgetDuration\n",
      "0     anon           5.397101\n",
      "1   user10           5.408333\n",
      "2  user120           6.566667\n",
      "3  user124           3.100000\n",
      "4  user125           5.555556\n"
     ]
    }
   ],
   "source": [
    "# Calculate average widget duration per UserID\n",
    "avg_widget_duration = data2.groupby('UserID')['WidgetDuration'].mean().reset_index()\n",
    "\n",
    "# Rename the column for clarity\n",
    "avg_widget_duration.rename(columns={'WidgetDuration': 'AvgWidgetDuration'}, inplace=True)\n",
    "\n",
    "# Display the result\n",
    "print(avg_widget_duration.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d813ed0-28a4-43dd-a7a0-1589bce54901",
   "metadata": {},
   "source": [
    "### \n",
    "## 6. Top 5 Most Viewed Recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a50151e8-2d04-4223-b92c-77a376aeaa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Most Viewed Recipes:\n",
      "     RecipeID  ViewCount\n",
      "0   P4D93R197          4\n",
      "1   P4D93R196          4\n",
      "2   P4D93R170          4\n",
      "3  P11D68R169          3\n",
      "4   P4D93R182          3\n"
     ]
    }
   ],
   "source": [
    "# Copy dataset\n",
    "data2 = main_dataset.copy()\n",
    "\n",
    "# Fill NaN with empty string so split works\n",
    "data2['ViewedRecipes'] = data2['ViewedRecipes'].fillna('')\n",
    "\n",
    "# Flatten all ViewedRecipes into individual RecipeIDs\n",
    "all_viewed = [recipe for sublist in data2['ViewedRecipes'].str.split(';') for recipe in sublist if recipe]\n",
    "\n",
    "# Count frequency of each RecipeID\n",
    "viewed_counts = Counter(all_viewed)\n",
    "\n",
    "# Convert to DataFrame for easy sorting and display\n",
    "top_viewed_df = pd.DataFrame(viewed_counts.items(), columns=['RecipeID', 'ViewCount']).sort_values(by='ViewCount', ascending=False)\n",
    "\n",
    "# Get top 5 most viewed recipes\n",
    "top_5_viewed = top_viewed_df.head(5).reset_index(drop=True)\n",
    "\n",
    "# Display as table\n",
    "print(\"Top 5 Most Viewed Recipes:\")\n",
    "print(top_5_viewed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28148b4-3fe5-4ad2-98bd-19e1d84fbc56",
   "metadata": {},
   "source": [
    "###\n",
    "## 7. Average Chat Duration per User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b29046df-3602-464a-b902-d3d979b9a670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Chat Length: 145.96 seconds (2.43 minutes)\n",
      "\n",
      "Top 10 Users by Average Chat Duration:\n",
      "     UserID  AverageChatDuration (seconds)\n",
      "11  user299                     385.000000\n",
      "7   user231                     304.000000\n",
      "21   user58                     282.000000\n",
      "16  user362                     266.000000\n",
      "24  user636                     214.000000\n",
      "13  user327                     214.000000\n",
      "26  user671                     169.666667\n",
      "20  user562                     152.000000\n",
      "0      anon                     145.230769\n",
      "12   user32                     145.000000\n"
     ]
    }
   ],
   "source": [
    "data3 = main_dataset.copy()\n",
    "\n",
    "# Convert 'ChatStart' and 'ChatEnd' columns to datetime\n",
    "data3['ChatStart'] = pd.to_datetime(data3['ChatStart'], errors='coerce')\n",
    "data3['ChatEnd'] = pd.to_datetime(data3['ChatEnd'], errors='coerce')\n",
    "\n",
    "# Drop rows where either ChatStart or ChatEnd is missing\n",
    "data3 = data3.dropna(subset=['ChatStart', 'ChatEnd'])\n",
    "\n",
    "# Calculate chat duration (in seconds)\n",
    "data3['ChatDuration'] = (data3['ChatEnd'] - data3['ChatStart']).dt.total_seconds()\n",
    "\n",
    "# Compute the average chat length (overall)\n",
    "average_chat_length = data3['ChatDuration'].mean()\n",
    "print(f\"Average Chat Length: {average_chat_length:.2f} seconds ({average_chat_length/60:.2f} minutes)\")\n",
    "\n",
    "# Compute average chat duration per user\n",
    "avg_chat_per_user = (\n",
    "    data3.groupby('UserID')['ChatDuration']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .sort_values(by='ChatDuration', ascending=False)\n",
    ")\n",
    "\n",
    "# Rename columns for clarity\n",
    "avg_chat_per_user.columns = ['UserID', 'AverageChatDuration (seconds)']\n",
    "\n",
    "# Display top 10 users with the longest average chat duration\n",
    "print(\"\\nTop 10 Users by Average Chat Duration:\")\n",
    "print(avg_chat_per_user.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199c6d65-5903-433e-8f18-9783e0b7d2e3",
   "metadata": {},
   "source": [
    "### \n",
    "## 8. Number of Sessions per User (Top 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "08b088fe-d5f2-45b0-b36f-58e773ef5944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserID\n",
      "anon       150\n",
      "user288     15\n",
      "user161     13\n",
      "user671     11\n",
      "user231     10\n",
      "user299     10\n",
      "user651     10\n",
      "user283     10\n",
      "user261      9\n",
      "user328      9\n",
      "Name: SessionStart, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate number of sessions per user\n",
    "sessions_per_user = data2.groupby('UserID')['SessionStart'].count().sort_values(ascending=False)\n",
    "\n",
    "# Display the result\n",
    "print(sessions_per_user.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a356bffc-166c-43e9-81cc-29b4e5cd00f6",
   "metadata": {},
   "source": [
    "###\n",
    "## 9. Most Common Pantry Items  (Top 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4090cbfc-4dde-435f-9b63-d32075cf8c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common pantry item: i314;i1172;i2362;i1432;i1062;i636;i474;i1459 (Count: 15)\n",
      "\n",
      "\n",
      "Top 10 Most Common Pantry items Pantry\n",
      "i314;i1172;i2362;i1432;i1062;i636;i474;i1459                15\n",
      "i382;i1889;i1093;i784;i1121;i1949;i1531                     13\n",
      "i1897;i2054;i773;i659;i364;i2312;i1830;i1382;i354;i1443     11\n",
      "i329;i2010;i1392;i1743;i1364;i1325;i656;i1585;i1974;i348    10\n",
      "i2189;i1238;i1567;i1644;i1611;i1010;i1418;i2056;i2472       10\n",
      "i2258;i743;i2369;i2368                                      10\n",
      "i1287;i1576;i876;i1218;i398;i2289;i1418;i2313               10\n",
      "i1385;i1850;i979;i1846;i1317;i781                            9\n",
      "i628;i1503;i1488;i851                                        9\n",
      "i1772;i1774;i2165;i1327;i1459;i618;i1405;i1427;i973          9\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data5 = main_dataset.copy()\n",
    "\n",
    "# Calculate pantry item counts\n",
    "pantry_counts = data5['Pantry'].value_counts()\n",
    "\n",
    "# Identify the most common pantry item\n",
    "most_common_pantry = pantry_counts.idxmax()\n",
    "most_common_count = pantry_counts.max()\n",
    "print(f\"Most common pantry item: {most_common_pantry} (Count: {most_common_count})\\n\\n\")\n",
    "\n",
    "# Plot top 10 pantry items\n",
    "top_pantry = pantry_counts.head(10)\n",
    "\n",
    "print('Top 10 Most Common Pantry items', top_pantry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37129799-7181-4b0d-b05e-7abcf178df63",
   "metadata": {},
   "source": [
    "###\n",
    "## 10. Most Common Ingredient Overall (Top 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3cbd191c-c17c-4f2b-a285-7ee6857e1389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common ingredient overall: i54;i2007;i1070;i27;i1083;i1806;i2042;i417;i476;i1080 (Count: 8)\n",
      "\n",
      "Top 10 Most Common Ingredients:\n",
      "                                          Ingredient  Count\n",
      "0  i54;i2007;i1070;i27;i1083;i1806;i2042;i417;i47...      8\n",
      "1  i1303;i17;i41;i2104;i1232;i1235;i1613;i2094;i2...      7\n",
      "2  i1603;i1170;i1514;i1576;i379;i2099;i1561;i916;...      6\n",
      "3  i356;i1345;i2405;i1509;i704;i1266;i1811;i166;i...      5\n",
      "4  i1141;i890;i1583;i236;i338;i130;i84;i1818;i236...      5\n",
      "5  i815;i1168;i585;i1317;i225;i1270;i1117;i1299;i...      4\n",
      "6  i492;i597;i516;i2031;i1691;i856;i1590;i54;i334...      4\n",
      "7  i936;i2435;i265;i2160;i1679;i1696;i780;i2200;i...      4\n",
      "8  i983;i2340;i1186;i942;i1214;i1801;i437;i820;i1...      4\n",
      "9  i690;i1946;i781;i2199;i837;i222;i1631;i1152;i1...      4\n"
     ]
    }
   ],
   "source": [
    "data6 = main_dataset.copy()\n",
    "\n",
    "# Combine all ingredients into a single list\n",
    "all_ingredients = data6['Ingredients'].dropna().apply(lambda x: str(x).split(','))\n",
    "flat_ingredients = [ingredient.strip() for sublist in all_ingredients for ingredient in sublist if ingredient.strip()]\n",
    "\n",
    "# Count occurrences of each ingredient\n",
    "ingredient_counts = Counter(flat_ingredients)\n",
    "\n",
    "# Most common ingredient overall\n",
    "most_common_ingredient, most_common_count = ingredient_counts.most_common(1)[0]\n",
    "print(f\"Most common ingredient overall: {most_common_ingredient} (Count: {most_common_count})\\n\")\n",
    "\n",
    "# Create DataFrame for top 10 most common ingredients\n",
    "top10_df = pd.DataFrame(ingredient_counts.most_common(10), columns=['Ingredient', 'Count'])\n",
    "\n",
    "# Display the table\n",
    "print(\"Top 10 Most Common Ingredients:\")\n",
    "print(top10_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f5e27a-f4e4-4af0-8d6d-d1e5c59a5f39",
   "metadata": {},
   "source": [
    "###\n",
    "## 11. Most Common Dietary Preference (Top 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ac38b136-926e-42f9-808d-c847bdd1d2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Most Common Dietary Preferences:\n",
      "   DietaryPreference  Count\n",
      "0              pref0     21\n",
      "1  pref2;pref1;pref3     18\n",
      "2              pref1     16\n",
      "3  pref2;pref1;pref0     15\n",
      "4              pref2     15\n"
     ]
    }
   ],
   "source": [
    "# Calculate counts of dietary preferences\n",
    "dietary_counts = data6['DietaryPreferences'].value_counts().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "dietary_counts.columns = ['DietaryPreference', 'Count']\n",
    "\n",
    "# Get top 5 dietary preferences\n",
    "top5_dietary = dietary_counts.head(5)\n",
    "\n",
    "# Display the table\n",
    "print(\"Top 5 Most Common Dietary Preferences:\")\n",
    "print(top5_dietary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f00f515-224a-4e95-9f23-88b45b8513d8",
   "metadata": {},
   "source": [
    "###\n",
    "## 12. Sessions by Device Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0f9d3ad7-19e0-4626-bdad-eaaaddf55a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions by Device Type:\n",
      " Device\n",
      "Desktop    172\n",
      "Tablet     169\n",
      "Mobile     159\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the count of sessions per device type\n",
    "sessions_by_device = data5['Device'].value_counts()\n",
    "\n",
    "# Display the result\n",
    "print(\"Sessions by Device Type:\\n\", sessions_by_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd05986-a6fc-4a11-9377-0b9b8a7557a8",
   "metadata": {},
   "source": [
    "###\n",
    "## 13. Average ingredient count per recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "694aca05-79c0-48a7-add8-180a5c8fae74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ingredient count per recipe: 10.00\n",
      "\n",
      "Top 5 most common ingredients:\n",
      "1. i2042 - 16 times\n",
      "2. i27 - 13 times\n",
      "3. i54 - 13 times\n",
      "4. i2099 - 12 times\n",
      "5. i1303 - 12 times\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Calculate ingredient counts per recipe ---\n",
    "data5['IngredientCount'] = data5['Ingredients'].dropna().apply(lambda x: len(str(x).split(';')))\n",
    "\n",
    "# --- Calculate average ingredient count ---\n",
    "avg_ingredient_count = data5['IngredientCount'].mean()\n",
    "\n",
    "# --- Combine all ingredients into one list to find most frequent ones ---\n",
    "all_ingredients = data5['Ingredients'].dropna().apply(lambda x: str(x).split(';'))\n",
    "flat_ingredients = [ingredient.strip() for sublist in all_ingredients for ingredient in sublist]\n",
    "\n",
    "# --- Count occurrences of each ingredient ---\n",
    "ingredient_counts = Counter(flat_ingredients)\n",
    "\n",
    "# --- Top 5 most common ingredients ---\n",
    "top5_ingredients = ingredient_counts.most_common(5)\n",
    "top5_names = [item[0] for item in top5_ingredients]\n",
    "top5_counts = [item[1] for item in top5_ingredients]\n",
    "\n",
    "# --- Print results ---\n",
    "print(f\"Average ingredient count per recipe: {avg_ingredient_count:.2f}\")\n",
    "print(\"\\nTop 5 most common ingredients:\")\n",
    "for i, (name, count) in enumerate(top5_ingredients, start=1):\n",
    "    average_ingredient_count = f\"{i}. {name} - {count} times\"\n",
    "    print(average_ingredient_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8198a772-3a23-4a1d-a735-8ef698daa388",
   "metadata": {},
   "source": [
    "###\n",
    "## 14. Most common allergy (Top 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c34e67d8-88f4-4722-b219-1c519d3b4e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common allergy: A48;A26;A23;A6;A41 (Count: 15)\n",
      "\n",
      "Top 5 Most Common Allergies:\n",
      "              Allergy  Count\n",
      "0  A48;A26;A23;A6;A41     15\n",
      "1   A37;A29;A9;A8;A12     13\n",
      "2         A27;A38;A26     11\n",
      "3  A15;A37;A39;A41;A3     10\n",
      "4             A17;A33     10\n"
     ]
    }
   ],
   "source": [
    "# Drop missing allergy values and clean data\n",
    "allergies = data5['Allergy'].dropna().apply(lambda x: str(x).strip())\n",
    "\n",
    "# Count allergy occurrences\n",
    "allergy_counts = Counter(allergies)\n",
    "\n",
    "# Most common allergy\n",
    "most_common_allergy, most_common_count = allergy_counts.most_common(1)[0]\n",
    "print(f\"Most common allergy: {most_common_allergy} (Count: {most_common_count})\\n\")\n",
    "\n",
    "# Create DataFrame for top 5 allergies\n",
    "top5_allergies_df = pd.DataFrame(allergy_counts.most_common(5), columns=['Allergy', 'Count'])\n",
    "\n",
    "# Display the table\n",
    "print(\"Top 5 Most Common Allergies:\")\n",
    "print(top5_allergies_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c027d350-d6bf-4875-aebd-2af3e996e28f",
   "metadata": {},
   "source": [
    "###\n",
    "## 15. Average Recepies Viewed per Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4d128c98-d5ec-406a-bb3b-d9343e4c5cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    UserID  AvgTimePerRecipeMinutes\n",
      "0     anon                 3.761616\n",
      "1   user10                 5.408333\n",
      "2  user120                 6.566667\n",
      "3  user124                 2.480000\n",
      "4  user125                 3.333333\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'WidgetDuration' is numeric\n",
    "data2['WidgetDuration'] = pd.to_numeric(data2['WidgetDuration'], errors='coerce')\n",
    "\n",
    "# Keep only positive durations\n",
    "data2 = data2[data2['WidgetDuration'] > 0]\n",
    "\n",
    "# Convert 'ViewedRecipes' to lists\n",
    "data2['ViewedRecipesList'] = data2['ViewedRecipes'].fillna('').apply(lambda x: x.split(';') if x else [])\n",
    "\n",
    "# Compute average time per recipe per user\n",
    "avg_time_per_recipe = data2.groupby('UserID').apply(\n",
    "    lambda x: x['WidgetDuration'].sum() / sum(len(v) for v in x['ViewedRecipesList'])\n",
    "              if sum(len(v) for v in x['ViewedRecipesList']) > 0 else 0\n",
    ").reset_index(name='AvgTimePerRecipeMinutes')\n",
    "\n",
    "# Display first few rows\n",
    "print(avg_time_per_recipe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a438e1f3-e2d2-4832-b6e3-18b580ec127f",
   "metadata": {},
   "source": [
    "### \n",
    "## 16. Save-to-view ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fdf7bc29-a40b-4e8b-a4f4-38a1c2ca8132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Viewed Recipies :  244\n",
      "Number of Saved Recipies :  63\n",
      "Percentage of Saved Recipes among Viewed: 25.82%\n"
     ]
    }
   ],
   "source": [
    "# Encode 'RecipeSaved' (True â†’ 2, False â†’ 1)\n",
    "data['RecipeSaved'] = data['RecipeSaved'].map({True: 2, False: 1})\n",
    "\n",
    "# Encode 'ViewedRecipes' (filled â†’ 2, NaN â†’ 1)\n",
    "data['ViewedRecipes'] = data['ViewedRecipes'].apply(lambda x: 2 if pd.notna(x) else 1)\n",
    "\n",
    "# Calculate counts\n",
    "saved_recipies = len(data[data['RecipeSaved'] == 2])\n",
    "viewed_recipies = len(data[data['ViewedRecipes'] == 2])\n",
    "\n",
    "# Print the Counts:\n",
    "print(f'Number of Viewed Recipies : ', viewed_recipies)\n",
    "print(f'Number of Saved Recipies : ', saved_recipies)\n",
    "\n",
    "\n",
    "# Calculate percentage\n",
    "percentage_saved_over_viewed = (saved_recipies / viewed_recipies) * 100 if viewed_recipies != 0 else 0\n",
    "\n",
    "# Display result\n",
    "print(f\"Percentage of Saved Recipes among Viewed: {percentage_saved_over_viewed:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6644ad20-2c10-49f8-b399-b2161f1c1c83",
   "metadata": {},
   "source": [
    "###\n",
    "## 17. Ingredient Substitution Analysis (Element-wise Comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "09cf9637-d915-4b84-936a-62d34032fd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ingredient Substitution Summary:\n",
      "    UserID  MatchCount  TotalIngredients  SubstitutionRate\n",
      "0     anon       106.0             360.0          0.705556\n",
      "1   user10         5.0              10.0          0.500000\n",
      "2  user120         1.0              10.0          0.900000\n",
      "3  user124         7.0              40.0          0.825000\n",
      "4  user125         4.0              20.0          0.800000\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Drop missing values in relevant columns ---\n",
    "data = data.dropna(subset=['Ingredients', 'AddedToCartItems', 'UserID'])\n",
    "\n",
    "# --- Step 2: Define function to calculate substitution stats ---\n",
    "def substitution_analysis(row):\n",
    "    ingredients = [i.strip() for i in str(row['Ingredients']).split(';') if i.strip()]\n",
    "    added = [i.strip() for i in str(row['AddedToCartItems']).split(';') if i.strip()]\n",
    "    \n",
    "    if not ingredients:\n",
    "        return pd.Series({'MatchCount': 0, 'TotalIngredients': 0, 'SubstitutionRate': None})\n",
    "    \n",
    "    match_count = sum(ing in added for ing in ingredients)\n",
    "    substitution_rate = 1 - (match_count / len(ingredients))\n",
    "    \n",
    "    return pd.Series({'MatchCount': match_count,\n",
    "                      'TotalIngredients': len(ingredients),\n",
    "                      'SubstitutionRate': substitution_rate})\n",
    "\n",
    "# --- Step 3: Apply function to each row ---\n",
    "data[['MatchCount', 'TotalIngredients', 'SubstitutionRate']] = data.apply(substitution_analysis, axis=1)\n",
    "\n",
    "# --- Step 4: Aggregate results per user ---\n",
    "user_substitution = (\n",
    "    data.groupby('UserID')\n",
    "        .agg({'MatchCount': 'sum', 'TotalIngredients': 'sum'})\n",
    "        .reset_index()\n",
    ")\n",
    "\n",
    "user_substitution['SubstitutionRate'] = 1 - (user_substitution['MatchCount'] / user_substitution['TotalIngredients'])\n",
    "\n",
    "# --- Step 5: Display results ---\n",
    "print(\" Ingredient Substitution Summary:\")\n",
    "print(user_substitution.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbc5b05-098b-4f50-95ba-d53a8b0dcea6",
   "metadata": {},
   "source": [
    "###\n",
    "## 18. Top allergy-causing ingredients (Top 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3d05beea-016d-40c8-8859-32081d8a8a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Allergy-Causing Ingredients:\n",
      "  Ingredient  AllergyCount\n",
      "0      i1234            18\n",
      "1      i2019            17\n",
      "2      i1691            15\n",
      "3      i1064            14\n",
      "4      i1631            13\n",
      "5       i738            12\n",
      "6       i107            12\n",
      "7       i175            12\n",
      "8      i1366            12\n",
      "9       i736            12\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Handle missing values and ensure proper string formatting ---\n",
    "data = data.dropna(subset=['Allergy', 'Ingredients']).copy()\n",
    "data['Allergy'] = data['Allergy'].astype(str)\n",
    "data['Ingredients'] = data['Ingredients'].astype(str)\n",
    "\n",
    "# --- Step 2: Define function to expand Allergyâ€“Ingredient pairs ---\n",
    "def map_allergy_to_ingredients(row):\n",
    "    allergies = [a.strip() for a in row['Allergy'].split(';') if a.strip()]\n",
    "    ingredients = [i.strip() for i in row['Ingredients'].split(';') if i.strip()]\n",
    "    return [(a, i) for a in allergies for i in ingredients]  # all possible pairs\n",
    "\n",
    "# --- Step 3: Flatten all pairs into a list ---\n",
    "pairs = sum(data.apply(map_allergy_to_ingredients, axis=1), [])\n",
    "\n",
    "# --- Step 4: Create DataFrame of all (Allergy, Ingredient) pairs ---\n",
    "pairs_df = pd.DataFrame(pairs, columns=['AllergyCode', 'Ingredient'])\n",
    "\n",
    "# --- Step 5: Count frequency of each ingredient across all allergies ---\n",
    "ingredient_allergy_count = pairs_df['Ingredient'].value_counts().reset_index()\n",
    "ingredient_allergy_count.columns = ['Ingredient', 'AllergyCount']\n",
    "\n",
    "# --- Step 6: Display top allergy-causing ingredients ---\n",
    "print(\"Top Allergy-Causing Ingredients:\")\n",
    "print(ingredient_allergy_count.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01b6290-b6a2-49cc-aff5-4c713c3f1668",
   "metadata": {},
   "source": [
    "###\n",
    "## 19. Active user streaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "86544772-b7d9-40df-82db-a4fd8361de84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Active User Streaks (Consecutive Days):\n",
      "     StreakID  StreakLength   UserID\n",
      "0           1            30     anon\n",
      "224         5             5  user671\n",
      "72          2             4  user283\n",
      "206         3             4  user636\n",
      "84          1             4  user299\n",
      "111         3             3  user328\n",
      "82          8             3  user288\n",
      "215         1             3  user651\n",
      "145         1             3  user431\n",
      "126         3             3  user362\n"
     ]
    }
   ],
   "source": [
    "data7 = main_dataset.copy()\n",
    "\n",
    "# --- Step 1: Ensure Date column is in datetime format ---\n",
    "data7['Date'] = pd.to_datetime(data7['Date'])\n",
    "\n",
    "# --- Step 2: Keep relevant columns and drop duplicates ---\n",
    "user_sessions = data7[['UserID', 'Date']].drop_duplicates().sort_values(['UserID', 'Date'])\n",
    "\n",
    "# --- Step 3: Calculate streaks ---\n",
    "streaks = []\n",
    "\n",
    "for user, group in user_sessions.groupby('UserID'):\n",
    "    group = group.sort_values('Date')\n",
    "    group['PrevDate'] = group['Date'].shift(1)\n",
    "    group['Gap'] = (group['Date'] - group['PrevDate']).dt.days\n",
    "    group['StreakID'] = (group['Gap'] != 1).cumsum()  # new streak if gap !=1\n",
    "    user_streaks = group.groupby('StreakID').size().reset_index(name='StreakLength')\n",
    "    user_streaks['UserID'] = user\n",
    "    streaks.append(user_streaks)\n",
    "\n",
    "streaks_df = pd.concat(streaks, ignore_index=True)\n",
    "\n",
    "# --- Step 4: Display top streaks ---\n",
    "print(\"Top Active User Streaks (Consecutive Days):\")\n",
    "active_users_streaks = streaks_df.sort_values('StreakLength', ascending=False).head(10)\n",
    "print(active_users_streaks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154b00cc-9911-403b-bdd3-be3054fdba8d",
   "metadata": {},
   "source": [
    "###\n",
    "## 20. Add-to-cart conversion rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0fa18fdd-afec-4146-9ef3-02045a8da8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Users by Add-to-Cart Conversion Rate (%):\n",
      "     UserID  AddToCartConversionRate\n",
      "47  user739                 4.000000\n",
      "15  user288                 3.000000\n",
      "19  user324                 3.000000\n",
      "2   user120                 3.000000\n",
      "6   user161                 2.600000\n",
      "18   user32                 2.333333\n",
      "33  user562                 2.250000\n",
      "12  user261                 2.250000\n",
      "8   user203                 2.000000\n",
      "10  user231                 2.000000\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Fill missing values and ensure strings ---\n",
    "data7['AddedToCartItems'] = data7['AddedToCartItems'].fillna('').astype(str)\n",
    "data7['AddToCart'] = data7['AddToCart'].fillna('').astype(str)\n",
    "\n",
    "# --- Step 2: Count items in each row ---\n",
    "data7['AddedToCartCount'] = data7['AddedToCartItems'].apply(lambda x: len(x.split(';')) if x else 0)\n",
    "data7['PurchasedCount'] = data7['AddToCart'].apply(lambda x: len(x.split(';')) if x else 0)\n",
    "\n",
    "# --- Step 3: Calculate conversion rate per user ---\n",
    "conversion_rate = data7.groupby('UserID').apply(\n",
    "    lambda x: x['PurchasedCount'].sum() / x['AddedToCartCount'].sum() \n",
    "              if x['AddedToCartCount'].sum() > 0 else 0\n",
    ").reset_index(name='AddToCartConversionRate')\n",
    "\n",
    "\n",
    "# --- Step 4: Sort by conversion rate descending ---\n",
    "conversion_rate_sorted = conversion_rate.sort_values('AddToCartConversionRate', ascending=False)\n",
    "\n",
    "\n",
    "# --- Step 5: Display top 10 users ---\n",
    "print(\"Top 10 Users by Add-to-Cart Conversion Rate (%):\")\n",
    "print(conversion_rate_sorted.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ddff6b-525c-47b3-9cc4-a77a9bded516",
   "metadata": {},
   "source": [
    "###\n",
    "## 21. Co-occurrence of allergies & preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d9146b9e-bab7-4895-82f3-ad17ee854d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplified Co-occurrence Table:\n",
      " DietaryPreferences       pref0  pref1  pref2  pref3\n",
      "Allergy                                            \n",
      "A10;A38;A9                   0      0      0      6\n",
      "A11;A22;A7;A47;A36;A20       0      8      0      8\n",
      "A15;A23;A44;A42;A51;A13      0      0      6      0\n",
      "A15;A37;A39;A41;A3           0     10     10     10\n",
      "A19;A27;A35;A16              2      0      2      2\n",
      "A22;A38                      9      0      0      0\n",
      "A23;A8;A35                   0      0      9      0\n",
      "A24;A23;A20;A4;A16           9      0      9      0\n",
      "A25;A26;A21;A9;A50;A41       0      0      7      7\n",
      "A27;A38;A10                  9      9      9      0\n",
      "A27;A38;A26                  0     11     11     11\n",
      "A2;A25;A23                   0      0      0      5\n",
      "A32;A23;A45;A42;A43          0      0      8      8\n",
      "A34;A3;A38                   6      6      0      6\n",
      "A42;A18;A4                   0      7      7      7\n",
      "A43;A39;A51;A29;A46          8      8      8      0\n",
      "A46;A3                       5      0      0      0\n",
      "A48;A26;A23;A6;A41          15     15     15      0\n",
      "A51;A43;A46                  7      0      0      0\n",
      "A5;A3;A33;A11;A46;A51        0      0      0      2\n",
      "A6;A29;A36                   0      8      0      0\n",
      "A7;A38;A28;A24               0      8      0      0\n"
     ]
    }
   ],
   "source": [
    "# Split DietaryPreferences into individual preferences directly in data2\n",
    "data7['DietaryPreferences'] = data7['DietaryPreferences'].str.split(';')\n",
    "data7 = data7.explode('DietaryPreferences')\n",
    "\n",
    "# Create co-occurrence table for Allergy vs individual DietaryPreferences\n",
    "co_occurrence_simple = pd.crosstab(data7['Allergy'], data7['DietaryPreferences'])\n",
    "print(\"Simplified Co-occurrence Table:\\n\", co_occurrence_simple)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f65453-59c9-4f65-af7f-7fcf51696578",
   "metadata": {},
   "source": [
    "###\n",
    "## 22. Session overlap detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c8dcff35-390e-4e81-9d9c-56741adae0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== SESSION OVERLAP DETECTION =====\n",
      "Total Users: 50\n",
      "Users with Overlapping Sessions: 3 (6.00%)\n",
      "\n",
      "Top Users with Most Overlaps:\n",
      "     UserID  OverlapCount\n",
      "0      anon          18.0\n",
      "14  user283           1.0\n",
      "25   user39           1.0\n"
     ]
    }
   ],
   "source": [
    "data8 = main_dataset.copy()\n",
    "\n",
    "# --- Step 1: Prepare and clean timestamps ---\n",
    "data8['Date'] = pd.to_datetime(data8['Date'], errors='coerce')\n",
    "\n",
    "# Combine Date + SessionStart/SessionEnd into proper datetime\n",
    "data8['SessionStart_dt'] = pd.to_datetime(\n",
    "    data8['Date'].astype(str) + ' ' + data8['SessionStart'], errors='coerce'\n",
    ")\n",
    "data8['SessionEnd_dt'] = pd.to_datetime(\n",
    "    data8['Date'].astype(str) + ' ' + data8['SessionEnd'], errors='coerce'\n",
    ")\n",
    "\n",
    "# Drop rows with missing session timestamps\n",
    "data8 = data8.dropna(subset=['SessionStart_dt', 'SessionEnd_dt'])\n",
    "\n",
    "# Ensure UserID is string type\n",
    "data8['UserID'] = data8['UserID'].astype(str)\n",
    "\n",
    "# --- Step 2: Sort sessions by UserID and start time ---\n",
    "data8 = data8.sort_values(by=['UserID', 'SessionStart_dt'])\n",
    "\n",
    "# --- Step 3: Detect overlapping sessions per user ---\n",
    "overlap_records = []\n",
    "\n",
    "for user, group in data8.groupby('UserID'):\n",
    "    sessions = group[['SessionStart_dt', 'SessionEnd_dt']].to_numpy()\n",
    "    for i in range(len(sessions) - 1):\n",
    "        curr_end = sessions[i][1]\n",
    "        next_start = sessions[i + 1][0]\n",
    "        if next_start < curr_end:\n",
    "            overlap_records.append(user)\n",
    "\n",
    "# --- Step 4: Summarize overlaps ---\n",
    "if overlap_records:\n",
    "    overlap_df = pd.DataFrame({'UserID': overlap_records})\n",
    "    overlap_summary = overlap_df['UserID'].value_counts().reset_index()\n",
    "    overlap_summary.columns = ['UserID', 'OverlapCount']\n",
    "else:\n",
    "    overlap_summary = pd.DataFrame(columns=['UserID', 'OverlapCount'])\n",
    "\n",
    "# Merge with total session counts per user\n",
    "user_summary = data8.groupby('UserID').size().reset_index(name='TotalSessions')\n",
    "user_summary = user_summary.merge(overlap_summary, on='UserID', how='left').fillna(0)\n",
    "\n",
    "# --- Step 5: Display summary ---\n",
    "total_users = data8['UserID'].nunique()\n",
    "overlapping_users = int((user_summary['OverlapCount'] > 0).sum())\n",
    "\n",
    "print(\"===== SESSION OVERLAP DETECTION =====\")\n",
    "print(f\"Total Users: {total_users}\")\n",
    "print(f\"Users with Overlapping Sessions: {overlapping_users} ({(overlapping_users/total_users)*100:.2f}%)\")\n",
    "\n",
    "if overlapping_users > 0:\n",
    "    print(\"\\nTop Users with Most Overlaps:\")\n",
    "    top_overlaps = user_summary[user_summary['OverlapCount'] > 0].sort_values(\n",
    "        by='OverlapCount', ascending=False\n",
    "    ).head()\n",
    "    print(top_overlaps[['UserID', 'OverlapCount']])\n",
    "else:\n",
    "    print(\"âœ… No session overlaps detected in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284e8f30-ef8e-4835-a63e-1d9db1cc2a54",
   "metadata": {},
   "source": [
    "###\n",
    "## 23. Drop-off analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7c493df4-04ac-435f-95c2-b34e2bc10d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== DROP-OFF ANALYSIS =====\n",
      "       RecipeID  ViewedRecipesCount  RecipeSavedCount  AddedToCartCount  \\\n",
      "285   P9D24R162                   5                 0                 0   \n",
      "298   P9D24R195                   5                 0                 0   \n",
      "261   P4D93R174                   5                 0                 0   \n",
      "254   P4D93R166                   4                 0                 0   \n",
      "84   P16D37R176                   4                 0                 0   \n",
      "315   P9D67R172                   3                 0                 0   \n",
      "268   P4D93R186                   3                 0                 0   \n",
      "289   P9D24R174                   3                 0                 0   \n",
      "280   P9D24R153                   3                 0                 0   \n",
      "313   P9D67R168                   3                 0                 0   \n",
      "\n",
      "     DropOffRate  \n",
      "285            5  \n",
      "298            5  \n",
      "261            5  \n",
      "254            4  \n",
      "84             4  \n",
      "315            3  \n",
      "268            3  \n",
      "289            3  \n",
      "280            3  \n",
      "313            3  \n"
     ]
    }
   ],
   "source": [
    "# --- Step 2: Ensure columns exist and clean data ---\n",
    "for col in ['ViewedRecipes', 'RecipeSaved', 'AddedToCartItems']:\n",
    "    if col not in data6.columns:\n",
    "        data6[col] = ''\n",
    "\n",
    "# Convert NaN to empty strings\n",
    "data8[['ViewedRecipes', 'RecipeSaved', 'AddedToCartItems']] = data8[['ViewedRecipes', 'RecipeSaved', 'AddedToCartItems']].fillna('')\n",
    "\n",
    "# --- Step 3: Convert to counts (handle string lists) ---\n",
    "def count_items(x):\n",
    "    if isinstance(x, str) and x.strip():\n",
    "        return len(x.split(';'))\n",
    "    elif isinstance(x, list):\n",
    "        return len(x)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "data8['ViewedRecipesCount'] = data8['ViewedRecipes'].apply(count_items)\n",
    "data8['RecipeSavedCount'] = data8['RecipeSaved'].apply(count_items)\n",
    "data8['AddedToCartCount'] = data8['AddedToCartItems'].apply(count_items)\n",
    "\n",
    "# --- Step 4: Compute Drop-off Rate ---\n",
    "# Drop-off rate = Views - max(Saves, Carts)\n",
    "data8['DropOffRate'] = data8['ViewedRecipesCount'] - data8[['RecipeSavedCount', 'AddedToCartCount']].max(axis=1)\n",
    "\n",
    "# --- Step 5: Aggregate at recipe level ---\n",
    "# Extract RecipeID if available\n",
    "if 'RecipeID' in data8.columns:\n",
    "    dropoff_summary = data8.groupby('RecipeID', as_index=False)[['ViewedRecipesCount', 'RecipeSavedCount', 'AddedToCartCount', 'DropOffRate']].sum()\n",
    "else:\n",
    "    dropoff_summary = data8[['ViewedRecipesCount', 'RecipeSavedCount', 'AddedToCartCount', 'DropOffRate']]\n",
    "\n",
    "# --- Step 6: Identify top drop-off recipes ---\n",
    "top_dropoff = dropoff_summary.sort_values(by='DropOffRate', ascending=False).head(10)\n",
    "\n",
    "print(\"===== DROP-OFF ANALYSIS =====\")\n",
    "print(top_dropoff)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44de822a-0d33-4a89-b40e-7e3cf618a6dd",
   "metadata": {},
   "source": [
    "###\n",
    "## 24. Feature Adoption Velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aad08fc3-34b2-41ac-9d85-4db718f8cc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== FEATURE ADOPTION VELOCITY =====\n",
      "Average Sessions Until Widget Use: 1.68\n",
      "Average Sessions Until Chat Use: 3.72\n",
      "\n",
      "    UserID  Widget_AdoptionVelocity  Chat_AdoptionVelocity\n",
      "0     anon                      1.0                    1.0\n",
      "1   user10                      4.0                    NaN\n",
      "2  user120                      1.0                    NaN\n",
      "3  user124                      1.0                    1.0\n",
      "4  user125                      4.0                    4.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Step 1: Ensure datetime conversion ---\n",
    "data8['SessionStart'] = pd.to_datetime(data8['SessionStart'], errors='coerce')\n",
    "\n",
    "# --- Step 2: Sort by UserID and SessionStart ---\n",
    "data8 = data8.sort_values(by=['UserID', 'SessionStart']).reset_index(drop=True)\n",
    "\n",
    "# --- Step 3: Define feature usage flags ---\n",
    "data8['UsedWidget'] = data8['WidgetStart'].notnull()\n",
    "data8['UsedChat'] = data8['ChatStart'].notnull()\n",
    "\n",
    "# --- Step 4: Calculate Feature Adoption Velocity per user ---\n",
    "feature_velocity = []\n",
    "\n",
    "for user, group in data8.groupby('UserID'):\n",
    "    group = group.reset_index(drop=True)\n",
    "    \n",
    "    # First session where user used the feature\n",
    "    widget_index = group.index[group['UsedWidget']].min() if group['UsedWidget'].any() else None\n",
    "    chat_index = group.index[group['UsedChat']].min() if group['UsedChat'].any() else None\n",
    "    \n",
    "    feature_velocity.append({\n",
    "        'UserID': user,\n",
    "        'Widget_AdoptionVelocity': widget_index + 1 if widget_index is not None else None,\n",
    "        'Chat_AdoptionVelocity': chat_index + 1 if chat_index is not None else None\n",
    "    })\n",
    "\n",
    "fav_result = pd.DataFrame(feature_velocity)\n",
    "\n",
    "# --- Step 5: Compute average adoption velocity ---\n",
    "avg_widget_velocity = fav_result['Widget_AdoptionVelocity'].mean()\n",
    "avg_chat_velocity = fav_result['Chat_AdoptionVelocity'].mean()\n",
    "\n",
    "# --- Step 6: Display Results ---\n",
    "print(\"===== FEATURE ADOPTION VELOCITY =====\")\n",
    "print(f\"Average Sessions Until Widget Use: {avg_widget_velocity:.2f}\")\n",
    "print(f\"Average Sessions Until Chat Use: {avg_chat_velocity:.2f}\\n\")\n",
    "print(fav_result.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4988b6d4-73f8-4689-8de9-562d655133f2",
   "metadata": {},
   "source": [
    "###\n",
    "## 25. Pantry-recipe similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3ca1f1df-fb4f-4b8a-9201-95066629915c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== PANTRY vs RECIPE INGREDIENTS SIMILARITY =====\n",
      "count    500.000000\n",
      "mean       0.002190\n",
      "std        0.011483\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.000000\n",
      "max        0.083333\n",
      "Name: PantryRecipeSimilarity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Step 1: Ensure Pantry and Ingredients are proper lists ---\n",
    "def to_list(x):\n",
    "    if pd.isna(x) or x == 'nan' or x == '':\n",
    "        return []\n",
    "    elif isinstance(x, str):\n",
    "        return x.split(';')\n",
    "    elif isinstance(x, list):\n",
    "        return x\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "data8['PantryList'] = data8['Pantry'].apply(to_list)\n",
    "data8['IngredientsList'] = data8['Ingredients'].apply(to_list)\n",
    "\n",
    "# --- Step 2: Define Jaccard similarity function ---\n",
    "def jaccard_similarity(list1, list2):\n",
    "    set1, set2 = set(list1), set(list2)\n",
    "    if not set1 and not set2:\n",
    "        return 0\n",
    "    return len(set1 & set2) / len(set1 | set2)\n",
    "\n",
    "# --- Step 3: Compute similarity per session ---\n",
    "data8['PantryRecipeSimilarity'] = data8.apply(\n",
    "    lambda row: jaccard_similarity(row['PantryList'], row['IngredientsList']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# --- Step 4: Summary statistics ---\n",
    "print(\"===== PANTRY vs RECIPE INGREDIENTS SIMILARITY =====\")\n",
    "pantry_similarity = data8['PantryRecipeSimilarity'].describe()\n",
    "print(pantry_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8da98b4-d87b-4740-8ad6-97b90879d74e",
   "metadata": {},
   "source": [
    "###\n",
    "## 26. Ingredient seasonal trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6bae2acd-46e3-494d-bbd9-6abe4a17dd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Ingredient Seasonal Trends Pivot Table =====\n",
      "MonthType          B    E    M\n",
      "IngredientsList               \n",
      "i1               0.0  1.0  0.0\n",
      "i10              0.0  1.0  0.0\n",
      "i100             1.0  0.0  0.0\n",
      "i1003            1.0  1.0  1.0\n",
      "i1008            0.0  0.0  1.0\n",
      "i1009            0.0  1.0  2.0\n",
      "i101             0.0  1.0  1.0\n",
      "i1011            0.0  1.0  1.0\n",
      "i1012            1.0  0.0  0.0\n",
      "i1013            0.0  0.0  1.0\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Ensure MonthType and Ingredients columns exist ---\n",
    "data8['IngredientsList'] = data8['Ingredients'].fillna('').apply(lambda x: x.split(';') if x else [])\n",
    "\n",
    "# --- Step 2: Explode the Ingredients for proper counting ---\n",
    "df_exploded = data8.explode('IngredientsList')\n",
    "\n",
    "# --- Step 3: Group by MonthType and Ingredient, count occurrences ---\n",
    "ingredient_counts = df_exploded.groupby(['MonthType', 'IngredientsList']).size().reset_index(name='Count')\n",
    "\n",
    "# --- Step 4: Pivot for plotting (Ingredients vs MonthType) ---\n",
    "pivot_table = ingredient_counts.pivot(index='IngredientsList', columns='MonthType', values='Count').fillna(0)\n",
    "\n",
    "# --- Step 5: Print the pivot table ---\n",
    "print(\"===== Ingredient Seasonal Trends Pivot Table =====\")\n",
    "print(pivot_table.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7b53c3-96d2-481f-a364-7ddac3607426",
   "metadata": {},
   "source": [
    "###\n",
    "## 27. Widget usage rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d9878491-2815-4fb6-8aec-c8db0e19da66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Status  Count   Rate\n",
      "0      Widget Used    244  0.488\n",
      "1  Widget Not Used    256  0.512\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Calculate counts ---\n",
    "total_sessions = len(data6)\n",
    "widget_used = data6['WidgetStart'].notnull().sum()\n",
    "widget_not_used = total_sessions - widget_used\n",
    "\n",
    "# --- Step 2: Create table (DataFrame) ---\n",
    "widget_table = pd.DataFrame({\n",
    "    'Status': ['Widget Used', 'Widget Not Used'],\n",
    "    'Count': [widget_used, widget_not_used],\n",
    "    'Rate': [widget_used/total_sessions, widget_not_used/total_sessions]\n",
    "})\n",
    "\n",
    "print(widget_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e3a2f4-a325-4e7b-9c0f-377b74ec294c",
   "metadata": {},
   "source": [
    "###\n",
    "## 28. Engagement Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f17d9eec-3f3a-4443-9754-2edc19caafe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Category  Count\n",
      "0  Both Chat & Widget     77\n",
      "1           Chat Only      0\n",
      "2         Widget Only    167\n",
      "3             Neither    256\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Create boolean columns for Chat and Widget usage ---\n",
    "data8['ChatUsed'] = data8['ChatStart'].notnull()\n",
    "data8['WidgetUsed'] = data8['WidgetStart'].notnull()\n",
    "\n",
    "# --- Step 2: Filter users using both Chat and Widget ---\n",
    "engagement_overlap = data8[(data8['ChatUsed'] == True) & (data8['WidgetUsed'] == True)]\n",
    "\n",
    "# --- Step 3: Count users in each category ---\n",
    "both_used = len(engagement_overlap)\n",
    "chat_only = len(data6[(data8['ChatUsed'] == True) & (data8['WidgetUsed'] == False)])\n",
    "widget_only = len(data6[(data8['ChatUsed'] == False) & (data8['WidgetUsed'] == True)])\n",
    "neither_used = len(data6[(data8['ChatUsed'] == False) & (data8['WidgetUsed'] == False)])\n",
    "\n",
    "# --- Step 4: Create a summary table ---\n",
    "engagement_table = pd.DataFrame({\n",
    "    'Category': ['Both Chat & Widget', 'Chat Only', 'Widget Only', 'Neither'],\n",
    "    'Count': [both_used, chat_only, widget_only, neither_used]\n",
    "})\n",
    "\n",
    "print(engagement_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeee8894-7ac5-4b65-b8b3-db34673e232b",
   "metadata": {},
   "source": [
    "###\n",
    "## 29. Cluster allergy patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7a4695d4-bd32-4be7-94f2-a98e33c18ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users per Allergy Cluster:\n",
      "AllergyCluster\n",
      "0     21\n",
      "1     30\n",
      "2    449\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# --- Step 1: Preprocess Allergy column ---\n",
    "data8['AllergyList'] = data8['Allergy'].fillna('').apply(lambda x: x.split(';') if x else [])\n",
    "\n",
    "# --- Step 2: One-hot encode allergy combinations ---\n",
    "mlb = MultiLabelBinarizer()\n",
    "allergy_encoded = mlb.fit_transform(data8['AllergyList'])\n",
    "allergy_df = pd.DataFrame(allergy_encoded, columns=mlb.classes_)\n",
    "\n",
    "# --- Step 3: Apply KMeans clustering ---\n",
    "k = 3  # number of clusters\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "data8['AllergyCluster'] = kmeans.fit_predict(allergy_df)\n",
    "\n",
    "# --- Step 4: Count users per cluster ---\n",
    "cluster_counts = data8['AllergyCluster'].value_counts().sort_index()\n",
    "print(\"Users per Allergy Cluster:\")\n",
    "print(cluster_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e295af-5c03-4ced-be41-008afa77f5f7",
   "metadata": {},
   "source": [
    "###\n",
    "## 30. Chat usage rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0a5e8cd2-07c6-4a45-8656-1b3affea71ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Category  Count\n",
      "0      Chat Used     77\n",
      "1  Chat Not Used    423\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Compute Chat usage ---\n",
    "total_sessions = data8.shape[0]\n",
    "chat_sessions = data8['ChatStart'].notnull().sum()\n",
    "chat_not_sessions = total_sessions - chat_sessions\n",
    "\n",
    "chat_usage_rate = chat_sessions / total_sessions\n",
    "chat_not_usage_rate = chat_not_sessions / total_sessions\n",
    "\n",
    "# --- Step 2: Create summary table ---\n",
    "chat_summary = pd.DataFrame({\n",
    "    'Category': ['Chat Used', 'Chat Not Used'],\n",
    "    'Count': [chat_sessions, chat_not_sessions]\n",
    "})\n",
    "\n",
    "print(chat_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6cd216-6b61-4125-836b-769d6130e5b2",
   "metadata": {},
   "source": [
    "###\n",
    "## 31. Widget-triggered saves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f3354af3-b69b-471f-bf16-9899e9b0a4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Category  Count\n",
      "0  Widget Triggered Saves    244\n",
      "1        Non-Widget Saves    256\n"
     ]
    }
   ],
   "source": [
    "# --- Step 0: Copy dataset ---\n",
    "data9 = main_dataset.copy()\n",
    "\n",
    "# --- Step 1: Create WidgetUsed flag ---\n",
    "data9['WidgetUsed'] = data9['WidgetStart'].notnull()\n",
    "\n",
    "# --- Step 2: Robust RecipeSaved count ---\n",
    "# Convert all values to string, split by ';', ignore empty strings\n",
    "data9['RecipeSavedCount'] = data9['RecipeSaved'].fillna('').apply(\n",
    "    lambda x: len([i for i in str(x).split(';') if i.strip() != ''])\n",
    ")\n",
    "\n",
    "# --- Step 3: Aggregate saves by WidgetUsed ---\n",
    "widget_saves = data9.loc[data9['WidgetUsed'], 'RecipeSavedCount'].sum()\n",
    "non_widget_saves = data9.loc[~data9['WidgetUsed'], 'RecipeSavedCount'].sum()\n",
    "\n",
    "# --- Step 4: Create summary table ---\n",
    "widget_save_summary = pd.DataFrame({\n",
    "    'Category': ['Widget Triggered Saves', 'Non-Widget Saves'],\n",
    "    'Count': [widget_saves, non_widget_saves]\n",
    "})\n",
    "\n",
    "print(widget_save_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc751eb-9e56-46e5-87a2-e0b42faea52f",
   "metadata": {},
   "source": [
    "###\n",
    "## 32. Tab-change impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c929790e-9c7e-4067-94f7-9d43f3f2e31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TabChangeFlag  EngagementScore\n",
      "0  No Tab Change         1.732620\n",
      "1    Tab Changed         1.706349\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Ensure RecipeSavedCount exists ---\n",
    "data9['RecipeSavedCount'] = data9['RecipeSaved'].fillna('').apply(lambda x: len([i for i in str(x).split(';') if i.strip() != '']))\n",
    "\n",
    "# --- Step 2: Ensure AddedToCartCount exists ---\n",
    "data9['AddedToCartCount'] = data9['AddedToCartItems'].fillna('').apply(lambda x: len([i for i in str(x).split(';') if i.strip() != '']))\n",
    "\n",
    "# --- Step 3: Define EngagementScore (you can adjust formula as needed) ---\n",
    "data9['EngagementScore'] = data9['RecipeSavedCount'] + data9['AddedToCartCount']\n",
    "\n",
    "# --- Step 4: Ensure TabChangeFlag exists ---\n",
    "data9['TabChangeFlag'] = data9['TabChange'].fillna(False)\n",
    "\n",
    "# --- Step 5: Compute average EngagementScore for TabChange vs No TabChange ---\n",
    "tab_change_metrics = data9.groupby('TabChangeFlag')['EngagementScore'].mean().reset_index()\n",
    "\n",
    "# --- Step 6: Map boolean to readable labels ---\n",
    "tab_change_metrics['TabChangeFlag'] = tab_change_metrics['TabChangeFlag'].map({\n",
    "    True: 'Tab Changed',\n",
    "    False: 'No Tab Change'\n",
    "})\n",
    "\n",
    "# --- Step 7: Display results ---\n",
    "print(tab_change_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e59cbc3-6c23-4aef-a728-cbead75f0e2f",
   "metadata": {},
   "source": [
    "###\n",
    "## 33. Ingredient diversity index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "82e352e3-b0e9-4daa-b1ce-93425d4bd919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ingredient  Count\n",
      "0      i2042     16\n",
      "1        i54     13\n",
      "2        i27     13\n",
      "3      i1303     12\n",
      "4      i1168     12\n",
      "5      i2099     12\n",
      "6      i1587     11\n",
      "7      i1811     11\n",
      "8      i1299     11\n",
      "9       i476     11\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Convert Ingredients column to lists if not already done ---\n",
    "data9['IngredientsList'] = data9['Ingredients'].fillna('').apply(lambda x: x.split(';') if x else [])\n",
    "\n",
    "# --- Step 2: Explode to get one ingredient per row ---\n",
    "df_exploded = data9.explode('IngredientsList')\n",
    "\n",
    "# --- Step 3: Count occurrences of each ingredient ---\n",
    "ingredient_counts = df_exploded['IngredientsList'].value_counts().reset_index()\n",
    "ingredient_counts.columns = ['Ingredient', 'Count']\n",
    "\n",
    "# --- Step 4: Display top 10 ingredients ---\n",
    "print(ingredient_counts.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46741dae-51eb-41f1-b4c9-17cbca6f3cd0",
   "metadata": {},
   "source": [
    "###\n",
    "## Saving  Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b0046b73-b760-42dd-88bb-70a09692cfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All 36 metrics saved successfully to 'Ankit_output.xlsx'!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# -------------------------------\n",
    "# Function to normalize metric to DataFrame\n",
    "# -------------------------------\n",
    "def to_dataframe(value, metric_name=None, top_n=None):\n",
    "    \"\"\"\n",
    "    Converts scalars, Series, DataFrames, or Counter to DataFrame for Excel.\n",
    "    \"\"\"\n",
    "    if isinstance(value, pd.DataFrame):\n",
    "        return value\n",
    "    elif isinstance(value, pd.Series):\n",
    "        if top_n:\n",
    "            value = value.head(top_n)\n",
    "        return value.reset_index()\n",
    "    elif isinstance(value, Counter):\n",
    "        df = pd.DataFrame(value.most_common(top_n if top_n else len(value)),\n",
    "                          columns=['Item', 'Count'])\n",
    "        return df\n",
    "    else:  # scalar\n",
    "        return pd.DataFrame({\"Metric\": [metric_name if metric_name else \"Value\"],\n",
    "                             \"Value\": [value]})\n",
    "\n",
    "# -------------------------------\n",
    "# Metrics dictionary\n",
    "# -------------------------------\n",
    "metrics = {\n",
    "    \"Save_to_View_Ratio\": to_dataframe(percentage_saved_over_viewed, metric_name=\"Percentage Saved over Viewed\"),\n",
    "    \"Top_5_Most_Viewed_Recipes\": to_dataframe(top_5_viewed, top_n=5),\n",
    "    \"Average_Chat_Duration_per_User\": to_dataframe(avg_chat_per_user, top_n=10),\n",
    "    \"Average_Widget_Load_Time\": to_dataframe(avg_load_time, metric_name=\"Average Widget Load Time\"),\n",
    "    \"Average_Widget_Duration_per_UserID\": to_dataframe(avg_widget_duration),\n",
    "    \"Peak_Usage_Hours\": to_dataframe(hourly_usage),\n",
    "    \"User_Engagement_Trends\": to_dataframe(engagement_trends, top_n=10),\n",
    "    \"Dietary_Preference_Distribution\": to_dataframe(dietary_distribution),\n",
    "    \"Number_of_Sessions_per_User_Top10\": to_dataframe(sessions_per_user, top_n=10),\n",
    "    \"Most_Common_Pantry_Items_Top10\": to_dataframe(top_pantry),\n",
    "    \"Most_Common_Ingredient_Overall_Top5\": to_dataframe(top10_df),\n",
    "    \"Most_Common_Dietary_Preference_Top5\": to_dataframe(top5_dietary),\n",
    "    \"Sessions_by_Device_Type\": to_dataframe(sessions_by_device),\n",
    "    \"Average_Ingredient_Count_per_Recipe\": to_dataframe(average_ingredient_count, metric_name=\"Average Ingredient Count\"),\n",
    "    \"Most_Common_Allergy_Top5\": to_dataframe(top5_allergies_df),\n",
    "    \"Users_with_Multiple_Allergies\": to_dataframe(multiple_allergies),\n",
    "    \"Allergy_Distribution_by_Region\": to_dataframe(allergy_by_region),\n",
    "    \"Average_Recipes_Viewed_per_Session\": to_dataframe(avg_time_per_recipe, top_n=10),\n",
    "    \"Rare_Ingredients_Bottom5pct\": to_dataframe(rare_ingredients, top_n=10),\n",
    "    \"Ingredient_Substitution_Analysis\": to_dataframe(user_substitution),\n",
    "    \"Top_Allergy_Causing_Ingredients_Top10\": to_dataframe(ingredient_allergy_count, top_n=10),\n",
    "    \"Active_User_Streaks\": to_dataframe(active_users_streaks),\n",
    "    \"Add_to_Cart_Conversion_Rate\": to_dataframe(conversion_rate_sorted, top_n=10),\n",
    "    \"Co_occurrence_of_Allergies_and_Preferences\": to_dataframe(co_occurrence_simple),\n",
    "    \"Session_Overlap_Detection\": to_dataframe(top_overlaps),\n",
    "    \"Drop_Off_Analysis\": to_dataframe(top_dropoff),\n",
    "    \"Feature_Adoption_Velocity\": to_dataframe(fav_result),\n",
    "    \"Pantry_Recipe_Similarity\": to_dataframe(pantry_similarity),\n",
    "    \"Ingredient_Seasonal_Trends\": to_dataframe(pivot_table),\n",
    "    \"Widget_Usage_Rate\": to_dataframe(widget_table),\n",
    "    \"Engagement_Overlap\": to_dataframe(engagement_table),\n",
    "    \"Cluster_Allergy_Patterns\": to_dataframe(cluster_counts),\n",
    "    \"Chat_Usage_Rate\": to_dataframe(chat_summary),\n",
    "    \"Widget_Triggered_Saves\": to_dataframe(widget_save_summary),\n",
    "    \"Tab_Change_Impact\": to_dataframe(tab_change_metrics),\n",
    "    \"Ingredient_Diversity_Index_Top10\": to_dataframe(ingredient_counts, top_n=10)\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# Excel export\n",
    "# -------------------------------\n",
    "output_file = \"Ankit_output.xlsx\"\n",
    "\n",
    "# Create file if it doesn't exist\n",
    "if not os.path.exists(output_file):\n",
    "    pd.DataFrame().to_excel(output_file)\n",
    "\n",
    "# Write all metrics to Excel\n",
    "with pd.ExcelWriter(output_file, mode=\"a\", engine=\"openpyxl\", if_sheet_exists=\"replace\") as writer:\n",
    "    for sheet_name, df in metrics.items():\n",
    "        df.to_excel(writer, sheet_name=sheet_name[:31], index=False)  # truncate to 31 chars\n",
    "\n",
    "print(f\"âœ… All 36 metrics saved successfully to '{output_file}'!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5b6e29-6efd-4cbb-9aef-8dfccc53a7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267637ed-bcb7-4620-8d56-63dc51010d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bd09a5-d0ab-4c7e-9a00-aff908638721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbedd2a4-f94f-453d-a1e5-d7c59d87b484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5efbb4-d5c6-4d06-b41a-09ab29ab13e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc9a9fa-c153-478c-8712-f161d8a3489a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c5c80f-7d8e-4be9-a698-096818a47698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
